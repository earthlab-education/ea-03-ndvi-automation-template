{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"earth-lab-logo-rgb.png\" width=\"150\" height=\"150\" />\n",
    "\n",
    "# Earth Analytics Education"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important  - Assignment Guidelines\n",
    "\n",
    "1. Before you submit your assignment to GitHub, make sure to run the entire notebook with a fresh kernel. To do this first, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart & Run All)\n",
    "2. Always replace the `raise NotImplementedError()` code with your code that addresses the activity challenge. If you don't replace that code, your notebook will not run.\n",
    "\n",
    "```\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "```\n",
    "\n",
    "3. Any open ended questions will have a \"YOUR ANSWER HERE\" within a markdown cell. Replace that text with your answer also formatted using Markdown.\n",
    "4. **DO NOT RENAME THIS NOTEBOOK File!** If the file name changes, the autograder will not grade your assignment properly.\n",
    "\n",
    "* Only include the package imports, code, and outputs that are required to run your homework assignment.\n",
    "* Be sure that your code can be run on any operating system. This means that:\n",
    "   1. the data should be downloaded in the notebook to ensure it's reproducible\n",
    "   2. all paths should be created dynamically using the `os.path.join`\n",
    "   3. sort lists of dated files even if they are sorted correctly by default on your machine\n",
    "\n",
    "## Follow to PEP 8 Syntax Guidelines & Documentation\n",
    "\n",
    "* Run the `autopep8` tool on all cells prior to submitting (HINT: hit shift + the tool to run it on all cells at once!\n",
    "* Use clear and expressive names for variables. \n",
    "* Organize your code to support readability.\n",
    "* Check for code line length\n",
    "* Use comments and white space sparingly where it is needed\n",
    "* Make sure all python imports are at the top of your notebook and follow PEP 8 order conventions\n",
    "* Spell check your Notebook before submitting it.\n",
    "\n",
    "For all of the plots below, be sure to do the following:\n",
    "\n",
    "* Make sure each plot has a clear TITLE and, where appropriate, label the x and y axes. Be sure to include UNITS in your labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Your Name Below \n",
    "**Your Name:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"colored-bar.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "48a86f37895d93d54dde5dcb921d939f",
     "grade": false,
     "grade_id": "hw-instructions",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Fire Management Regimes - Yosemite National Park\n",
    "\n",
    "For this assignment, you will write code to generate a plot of the mean normalized difference vegetation index (NDVI) over time for the Illilouette watershed near Yosemite National Park, USA.\n",
    "\n",
    "The eventual goal is to characterize different fire regimes by comparing Illilouette watershed over time with control watersheds using the Normalized Burn Ratio index. This assignment will get you started on that larger goal.\n",
    "\n",
    "## Assignment Goals:\n",
    "  1. Download the Illilouette watershed boundary\n",
    "  2. Use a pre-written `EarthExplorerDownloader` *class* to automatically download and decompress one year of Landsat Analysis Ready Multispectral data\n",
    "  3. Load the downloaded data into a single xarray DataArray, performing necessary pre-processing tasks\n",
    "  4. Compute and plot the mean NDVI in the watershed over time\n",
    "\n",
    "## About the Earth Explorer M2M Interface\n",
    "The data that you will use for this week is available Earth Explorer. However, you will need more data that you can reasonably download using the web interface for Earth Explorer. Instead, you will need to write some code to download data using the Earth Explorer [Machine to Machine (M2M) interface](https://m2m.cr.usgs.gov/).\n",
    "\n",
    "**You will need to [sign up for access the the M2M interface](https://ers.cr.usgs.gov/profile/access) to complete this assignment -- please note that it can take a day or two to get access**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5dd24c4b18f88fb48f92ab0e69b3a4d7",
     "grade": true,
     "grade_id": "cell-950f8fcce17a19b5",
     "locked": false,
     "points": 6,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "20489880accefdb27a2f10ca8cc97835",
     "grade": false,
     "grade_id": "student-imports-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": [
     "hide",
     "hide_output"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5f3d65319f10810fc23ed0b8bc60fced",
     "grade": false,
     "grade_id": "cell-c18d242310199458",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Background: Fire Management in California, USA\n",
    "\n",
    "[Review this paper comparing runoff ratio in two California watersheds](https://link.springer.com/article/10.1007/s10021-016-0048-1). (You should have access from the CU libraries using your IdentiKey)\n",
    "\n",
    "In the cell below, write a summary of the article, including a site description. What are the implications of this study for wildfire management practices?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bb46a83193852f597f75b7c36fbff236",
     "grade": true,
     "grade_id": "cell-4a07b3e5d8858146",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define your study area\n",
    "\n",
    "You are interested in checking the NDVI over time at the Illilouette watershed.\n",
    "\n",
    "### Download watershed boundary\n",
    "\n",
    "1. Start by downloading and caching the watershed boundary dataset for 2-digit HUC 18 (roughly California). Watershed Boundary Dataset (WBD) download urls can be found at [USGS's National Map Staged Products site](https://prd-tnm.s3.amazonaws.com/index.html?prefix=StagedProducts/Hydrography/WBD/HU2/Shape/) **Open your zip file path with 'wb' (binary write) permissions in order to dump the response content there.**\n",
    "\n",
    "2. The zip file will contain shapefiles of watersheds of different [Hydrologic Unit Code (HUC) lengths](https://nas.er.usgs.gov/hucs.aspx). You will need to unzip the downloaded file using the standard library `zipfile`. To access the WBD data. The `Shape` > `WBDHU12.shp` file contains the basins for this study.\n",
    "  * Check out this [example of how to access `.zip` file contents](https://docs.python.org/3/library/zipfile.html#zipfile.ZipFile.open). Once you have a zipfile object, use the `.extractall()` method to unzip.\n",
    "  * A second example may be found in the EarthExplorerDownloader class defined below\n",
    "\n",
    "3. Select your watershed of interest from the `GeoDataFrame`. Note that the WBD does **not** contain gage numbers as are referenced in the paper, so you will have to find the watershed by name. You can **search for strings in a GeoDataFrame column using the `.str.contains()` method** of GeoSeries.\n",
    "\n",
    "**Return the filtered GeoDataFrame with one row per watershed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cd893c7c359ef1f5e27f9a32f1e01568",
     "grade": false,
     "grade_id": "cell-e4d31b67c4835429",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a site map\n",
    "\n",
    "Your `folium` map should contains your watershed boundaries along with a terrain basemap. Bonus - label each watershed boundary layer and tooltip with its name. \n",
    "\n",
    "Check out some [example code from the folium documentation](https://python-visualization.github.io/folium/quickstart.html#GeoJSON/TopoJSON-Overlays)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundaries.centroid.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "88b5d56acf2445153b8090b0d541f505",
     "grade": false,
     "grade_id": "cell-a1c7a78987f0afd9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e112875dd738b87c6386582c408f32c1",
     "grade": false,
     "grade_id": "cell-8bb64b442465fb40",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "## Download Multispectral Data Using the Machine to Machine (M2M) Earth Explorer API\n",
    "\n",
    "**You will need to have your Earth Explorer account activated to work with M2M to complete this section**\n",
    "\n",
    "To start, download 6 months of multispectral surface reflectance data using the following parameters:\n",
    "  - Use the \"Landsat 4-9 C2 U.S. ARD\" dataset\n",
    "  - Use the watershed boundary as the spatial boundary\n",
    "  - 6 months of data (you will find that you need to make changes to the code to download more than 100 scenes)\n",
    "\n",
    "The cell below contains two classes that can help you with the download. Your task here is to:\n",
    "  * **Add descriptive docstrings to each class and method in the cell below**. What does each method do?\n",
    "  * In the cell below, initialize the class and use it to complete the Earth Explorer download. You should only need a few lines of code to complete the download (note that it can take in the vicinity of 20 minutes for Earth Explorer to prepare your download, and the class below should update you on the status of your download every 30 seconds.)\n",
    "  \n",
    "The steps for downloading using the classes below are:\n",
    "  1. Define the bounding box\n",
    "  2. Initialize the EarthExplorerDownloader instance\n",
    "    * one year of data (Start with less to test your code!)\n",
    "    * only download data needed to cover the watershed boundary\n",
    "    * Dataset: \"Landsat 4-9 C2 U.S. ARD\"\n",
    "  3. Submit a download request\n",
    "  4. Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BBox:\n",
    "    def __init__(self, llx, lly, urx, ury):\n",
    "        self.llx, self.lly, self.urx, self.ury = llx, lly, urx, ury\n",
    "\n",
    "    @property\n",
    "    def spatial_filter(self):\n",
    "        return {\n",
    "            'filterType': \"mbr\",\n",
    "            'lowerLeft': {'latitude': self.lly, 'longitude': self.llx},\n",
    "            'upperRight': {'latitude': self.ury, 'longitude': self.urx}}\n",
    "\n",
    "class EarthExplorerDownloader:\n",
    "\n",
    "    base_url = \"https://m2m.cr.usgs.gov/api/api/json/stable/{endpoint}\"\n",
    "    product_filter = {'productName': 'C2 ARD Tile Surface Reflectance Bundle Download'}\n",
    "    dld_file_tmpl = '{display_id}.tar'\n",
    "\n",
    "    def __init__(self, dataset, label, bbox, start, end):\n",
    "        self.api_key = None\n",
    "        self.login()\n",
    "        \n",
    "        self.dataset, self.label = dataset, label\n",
    "        self.bbox, self.start, self.end = bbox, start, end\n",
    "        \n",
    "        self.temporal_filter = {'start': start, 'end': end}\n",
    "        self.acquisition_filter = self.temporal_filter\n",
    "        \n",
    "        self.path_tmpl = os.path.join(self.label, self.dld_file_tmpl)\n",
    "        if not os.path.exists(label):\n",
    "            os.makedirs(label)\n",
    "        \n",
    "        self._dataset_alias = None\n",
    "\n",
    "    def get_ee_login_info(self, info_type):\n",
    "        # Generate and store key\n",
    "        key_path = os.path.join(pathlib.Path.home(), '.ee_key')\n",
    "        if not os.path.exists(key_path):\n",
    "            print('Generating new key...')\n",
    "            key = Fernet.generate_key()\n",
    "            with open(key_path, 'wb') as key_file:\n",
    "                key_file.write(key)\n",
    "        with open(key_path, 'rb') as key_file:\n",
    "            key = key_file.read()\n",
    "        fernet = Fernet(key)\n",
    "\n",
    "        # Collect and store login info\n",
    "        info_path = os.path.join(\n",
    "            pathlib.Path.home(),\n",
    "            '.ee_{}'.format(info_type))\n",
    "        if not os.path.exists(info_path):\n",
    "            info = input('Enter {}: '.format(info_type))\n",
    "            with open(info_path, 'wb') as info_file:\n",
    "                info_file.write(fernet.encrypt(bytes(info, 'utf-8')))\n",
    "        with open(info_path, 'rb') as info_file:\n",
    "            return fernet.decrypt(info_file.read()).decode(\"utf-8\")\n",
    "\n",
    "    def login(self):\n",
    "        if self.api_key is None:\n",
    "            login_payload = {\n",
    "                'username': self.get_ee_login_info('username'), \n",
    "                'password': self.get_ee_login_info('password')}\n",
    "            self.api_key = self.post(\"login\", login_payload)\n",
    "            print('Login Successful')\n",
    "        \n",
    "    @property\n",
    "    def headers(self):\n",
    "        if self.api_key is None:\n",
    "            return None\n",
    "        return  {'X-Auth-Token': self.api_key}\n",
    "    \n",
    "    def logout(self):\n",
    "        self.post(\"logout\", None)\n",
    "        print(\"Logged Out\\n\\n\")\n",
    "\n",
    "    def post(self, endpoint, data):\n",
    "        # Send POST requests\n",
    "        url = self.base_url.format(endpoint=endpoint)\n",
    "        response = requests.post(url, json.dumps(data), headers=self.headers)\n",
    "        \n",
    "        # Raise any HTTP Errors\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Return data\n",
    "        return response.json()['data']\n",
    "    \n",
    "    @property\n",
    "    def dataset_alias(self):\n",
    "        if self._dataset_alias is None:\n",
    "            print(\"Searching datasets...\")\n",
    "            params = {\n",
    "                'datasetName': self.dataset,\n",
    "                'spatialFilter': self.bbox.spatial_filter,\n",
    "                'temporalFilter': self.temporal_filter}\n",
    "            datasets = self.post(\"dataset-search\", params)\n",
    "            \n",
    "            # Get a single dataset alias\n",
    "            if len(datasets) > 1:\n",
    "                print(datasets)\n",
    "                raise ValueError('Multiple datasets found - refine search.')\n",
    "            self._dataset_alias = datasets[0]['datasetAlias']\n",
    "            \n",
    "            print('Using dataset alias: {}'.format(self._dataset_alias))\n",
    "        return self._dataset_alias\n",
    "    \n",
    "    def find_scene_ids(self):\n",
    "        params = {\n",
    "            'datasetName': self.dataset_alias,\n",
    "            'startingNumber': 1,\n",
    "            \n",
    "            'sceneFilter': {\n",
    "                'spatialFilter': self.bbox.spatial_filter,\n",
    "                'acquisitionFilter': self.acquisition_filter}}\n",
    "        \n",
    "        print(\"Searching scenes...\")\n",
    "        scenes = self.post(\"scene-search\", params)\n",
    "        print('Found {} scenes'.format(scenes['recordsReturned']))\n",
    "        return scenes\n",
    "    \n",
    "    def find_available_product_info(self):\n",
    "        scenes = self.find_scene_ids()\n",
    "        params = {\n",
    "            'datasetName': self.dataset_alias, \n",
    "            'entityIds': [scene['entityId'] for scene in scenes['results']]}\n",
    "        products = self.post(\"download-options\", params)\n",
    "\n",
    "        # Aggregate a list of available products\n",
    "        product_info = []\n",
    "        for product in products:\n",
    "            # Make sure the product is available for this scene\n",
    "            if product['available']==True or product['proxied']==True:\n",
    "                product_info.append({\n",
    "                    'entityId': product['entityId'],\n",
    "                    'productId': product['id']})\n",
    "        if not product_info:\n",
    "            raise ValueError('No available products.')\n",
    "        return product_info\n",
    "\n",
    "    def submit_download_request(self):\n",
    "        product_info = self.find_available_product_info()\n",
    "        # Did we find products?\n",
    "        if product_info:\n",
    "            # Request downloads\n",
    "            params = {\n",
    "                'downloads': product_info,\n",
    "                'label': self.label}\n",
    "            downloads = self.post(\"download-request\", params)\n",
    "            print('Downloads staging...')\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                'No products found with the specified boundaries.')\n",
    "    \n",
    "    def check_download_status(self):\n",
    "        params = {'label': self.label}\n",
    "        downloads = self.post(\"download-retrieve\", params)\n",
    "        return downloads\n",
    "    \n",
    "    def wait_for_available_downloads(self, timeout=None):\n",
    "        keep_waiting = True\n",
    "        while keep_waiting:\n",
    "            downloads = self.check_download_status()\n",
    "            n_queued = downloads['queueSize']\n",
    "            keep_waiting = n_queued > 0\n",
    "            if keep_waiting:\n",
    "                print(\"\\n\", n_queued,\n",
    "                      \"downloads queued but not yet available. \"\n",
    "                      \"Waiting for 30 seconds.\\n\")\n",
    "                time.sleep(30)\n",
    "            \n",
    "            if not timeout is None:\n",
    "                timeout -= 30\n",
    "                if timeout < 0:\n",
    "                    break\n",
    "\n",
    "        return downloads\n",
    "        \n",
    "    def download(self, wait=True, timeout=None, override=True):\n",
    "        # Check download status\n",
    "        if wait:\n",
    "            downloads = self.wait_for_available_downloads(timeout=timeout)\n",
    "        else:\n",
    "            downloads = self.check_download_status()\n",
    "            \n",
    "        available_or_proxied = (\n",
    "            downloads['available'] \n",
    "            + [dld for dld in downloads['requested'] if dld['statusCode']=='P'])\n",
    "        if not available_or_proxied:\n",
    "            raise ValueError('No available downloads.')\n",
    "        \n",
    "        # Download available downloads\n",
    "        for download in available_or_proxied:\n",
    "            # Filter out products\n",
    "            if not self.product_filter is None:\n",
    "                match = [download[k]==v for k, v in self.product_filter.items()]\n",
    "                if not all(match):\n",
    "                    continue\n",
    "            \n",
    "            # Download and save compressed file\n",
    "            dld_path = self.path_tmpl.format(display_id=download['displayId'])\n",
    "            # Cache downloads\n",
    "            if override or not os.path.exists(dld_path):\n",
    "                print('Saving download: {}'.format(download['displayId']))\n",
    "                with open(dld_path, 'wb') as dld_file:\n",
    "                    response = requests.get(download['url'])\n",
    "                    dld_file.write(response.content)\n",
    "            \n",
    "            self.uncompress(dld_path)\n",
    "                    \n",
    "    def uncompress(self, download_path):\n",
    "        # Extract compressed files\n",
    "        with tarfile.TarFile(download_path, 'r') as dld_tarfile:\n",
    "            dld_tarfile.extractall(self.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca763f527b6699ef7b00a04b759283d6",
     "grade": true,
     "grade_id": "cell-510047e3b6fb8ed8",
     "locked": false,
     "points": 20,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "58d52128e85a1fd7a6e59682c1753a04",
     "grade": false,
     "grade_id": "ndvi-mean-site-instructions",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# A Time Series of Mean NDVI For the Illilouette Watershed\n",
    "\n",
    "Now that you have downloaded some multispectral data, you can compute NDVI over time. Over a long period of time, these computations can help to characterize the fire management regimes in different watersheds.\n",
    "\n",
    "## Get information about the files you downloaded\n",
    "Using the `glob` library, create a `DataFrame` containing the following information about each scene you downloaded:\n",
    "  - Band raster file path\n",
    "  - Corresponding cloud/aerosol QA path (file ending in 'QA_AEROSOL.TIF')\n",
    "  - Date\n",
    "  - Band\n",
    "\n",
    "Hints:\n",
    " * If you have a list of dictionaries with matching keys, you can make a DataFrame using `pd.DataFrame(data=list_of_dictionaries)`.\n",
    " * Need to look at some example file names? Use the code `ls | head -n 25` in `bash` to view the first 25 of the files you downloaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1d3911f4923adabb86b03cfe211aec9c",
     "grade": true,
     "grade_id": "pseudo-code",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1ca4067d020e76c52d738d0820b05075",
     "grade": false,
     "grade_id": "single-scene-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "05256960cbb34795d2f2862014804f2c",
     "grade": false,
     "grade_id": "cell-7bcbb6a14f49ee08",
     "locked": true,
     "points": 25,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "## Clip and mask Landsat data\n",
    "\n",
    "Write a function, multiple functions or a class to reproducibly perform the following steps:\n",
    "  * open a raster in your DataFrame\n",
    "  * clip it to the watershed boundary\n",
    "  * mask data outside the valid range of 0-40000\n",
    "  * mask data covered by clouds\n",
    "    * open the corresponding aerosol QA raster\n",
    "    * mask locations with values in [328, 392, 840, 904, 1350, 352, 368, 416, 432, 480, 864, 880, 928, 944, 992, 480, 992]\n",
    "  * filter out data that is more than 50% masked\n",
    "  \n",
    "Not every step must be in the function - use your judgement about the most readable and DRY approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1b78432f72c452b47ae3d4a49696337",
     "grade": false,
     "grade_id": "cell-d6a842e27632b972",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8cd89e1a8aac24a2558d847ca9a1541b",
     "grade": false,
     "grade_id": "cell-99a4412518925557",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "Test your process by plotting your data using the following code:\n",
    "\n",
    "```python\n",
    "landsat_ds.plot(col='date', col_wrap=5, \n",
    "                subplot_kws={'xticklabels': 'off',\n",
    "                             'yticklabels': 'off'})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8043bfba2449fb959ec6c3c29fd21520",
     "grade": false,
     "grade_id": "cell-5b3f7f3bb8094d5a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5f3e9e5c2f4dd0daa63700529270d660",
     "grade": false,
     "grade_id": "cell-c65b14e2297bad61",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "## Plot the mean NBR over time\n",
    "\n",
    "In the cell below, summarize and plot your DataArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6ba956eb666acb0fb7a858f3f5d24ed4",
     "grade": false,
     "grade_id": "cell-d0c54f789916a3c1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0a18a93bef486192c421801113778ebc",
     "grade": true,
     "grade_id": "cell-f5226184b5a8e6ed",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bcc0e446306a9db445d1ab243227c563",
     "grade": false,
     "grade_id": "pep8-formatting-check",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "# Do not edit this cell! (20 points)\n",
    "\n",
    "The notebook will also be checked for overall clean code requirements as specified at the **top** of this notebook. Some of these requirements include (review the top cells for more specifics): \n",
    "\n",
    "* Notebook begins at cell [1] and runs on any machine in its entirety.\n",
    "* PEP 8 format is applied throughout (including lengths of comment and code lines).\n",
    "* No additional code or imports in the notebook that is not needed for the workflow.\n",
    "* Notebook is fully reproducible. This means:\n",
    "   * reproducible paths using the os module.\n",
    "   * data downloaded using code in the notebook.\n",
    "   * all imports at top of notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
